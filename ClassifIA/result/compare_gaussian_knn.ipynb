{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "f6f12d99",
            "metadata": {
                
            },
            "outputs": [
                
            ],
            "source": [
                "from graphviz import Digraph\n\ng = Digraph('G')\ng.attr(rankdir='LR')\ng.node_attr.update(style='filled', fillcolor='white', shape='box')\ncolors = ['green','red','blue','orange']\nwith g.subgraph(name='cluster_0') as d:\n\td.attr(style='filled', fillcolor='antiquewhite1')\n\td.attr(rank='same')\n\td.edge('../input/digit-recognizer/train.csv','train')\n\td.edge('../input/digit-recognizer/test.csv','test')\n\td.edge('train','rmNull')\n\td.edge('test','rmNull')\n\td.edge('rmNull','rmOutliers')\n\td.edge('rmOutliers','PreProssTrain')\n\td.edge('rmOutliers','PreProssTest')\n\td.attr(label='Data pre-processing')\nwith g.subgraph(name='cluster_1') as t:\n\tt.attr(style='filled', fillcolor='palegreen3')\n\tt.attr(rank='same')\n\tt.node('t1', style='filled', fillcolor='thistle')\n\tt.edge('PreProssTrain','t1')\n\tt.edge('PreProssTest','t1')\n\tt.edge('t1','t1_minMax01')\n\tt.edge('t1_minMax01','t1_pca01')\n\tt.node('t2', style='filled', fillcolor='thistle')\n\tt.edge('PreProssTrain','t2')\n\tt.edge('PreProssTest','t2')\n\tt.edge('t2','t2_minMax01')\n\tt.edge('t2_minMax01','t2_pca02')\n\tt.attr(label='Data Transformation')\nwith g.subgraph(name='cluster_2') as tr:\n\ttr.attr(style='filled', fillcolor='paleturquoise')\n\ttr.attr(rank='same')\n\ttr.node('gaussian1', style='filled', fillcolor='peachpuff')\n\ttr.edge('t1_pca01', 'gaussian1')\n\ttr.node('knn1', style='filled', fillcolor='peachpuff')\n\ttr.edge('t2_pca02', 'knn1')\n\ttr.node('knn2', style='filled', fillcolor='peachpuff')\n\ttr.edge('t2_pca02', 'knn2')\n\ttr.attr(label='Training')\nwith g.subgraph(name='cluster_3') as val:\n\tval.attr(style='filled', fillcolor='antiquewhite3')\n\tval.attr(rank='same')\n\tval.node('cross_validate')\n\tval.edge('gaussian1','cross_validate')\n\tval.edge('knn1','cross_validate')\n\tval.attr(label='Validation')\nwith g.subgraph(name='cluster_4') as comp:\n\tcomp.attr(style='filled', fillcolor='antiquewhite2')\n\tcomp.attr(rank='same')\n\tcomp.node('cross_validate')\n\tcomp.node('compare',shape='record', label='comparison |{ test_acc weight 10 | fit_time weight 3 }')\n\tcomp.edge('cross_validate','compare')\n\tcomp.attr(label='Comparison')\nwith g.subgraph(name='cluster_5') as report:\n\treport.attr(style='filled', fillcolor='azure2')\n\treport.attr(rank='same')\n\treport.node('REPORT',shape='record', label='REPORT | { ARRAY RESULT | CLOUD DOT  }')\n\treport.edge('compare','REPORT')\n\treport.attr(label='Display Report')\ng"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "42234fee",
            "metadata": {
                
            },
            "source": "IMPORTS"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "bcb533a5",
            "metadata": {
                
            },
            "outputs": [
                
            ],
            "source": [
                "%pylab inline\n",
                "#%pylab\n",
                "import numpy as np\n",
                "from sklearn import datasets, svm, metrics\n",
                "import pandas as pd\n",
                "from matplotlib import pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from matplotlib import pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.model_selection import cross_val_score\n",
                "from sklearn import metrics\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn import preprocessing\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score,precision_score, f1_score, roc_curve, auc, make_scorer,roc_auc_score \n",
                "from sklearn.metrics import classification_report\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from scipy import stats\n",
                "from sklearn.model_selection import RandomizedSearchCV\n",
                "from scipy.stats import randint as sp_randint\n",
                "from sklearn.model_selection import cross_validate\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.ensemble import AdaBoostClassifier\n",
                "from sklearn.gaussian_process import GaussianProcessClassifier\n",
                "from sklearn.gaussian_process.kernels import RBF\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "import matplotlib.pyplot as plt\n",
                "import operator\n",
                ""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8de2d4ce",
            "metadata": {
                
            },
            "source": "PREPROCESSING"
        },
        {
            "cell_type": "markdown",
            "id": "034697a3",
            "metadata": {
                
            },
            "source": "DATASET IMPORT"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "33349001",
            "metadata": {
                
            },
            "outputs": [
                
            ],
            "source": [
                "## DATASET IMPORT\n",
                "import pandas as pd\n",
                "try:\n",
                "\tdataTrainSet = pd.read_csv('../input/digit-recognizer/train.csv')\n",
                "\tdataTestSet = pd.read_csv('../input/digit-recognizer/test.csv')\n",
                "except FileNotFoundError:\n",
                "\tprint('The path of the dataset is invalid')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5c05cbc1",
            "metadata": {
                
            },
            "source": "PREPROCESSING"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "7586ab58",
            "metadata": {
                
            },
            "outputs": [
                
            ],
            "source": [
                "###### ---- PREPROCESSING PHASE ---- ######\n",
                "## PREPROCESS : RMNULL \n",
                "dataTrainSet.dropna()\n",
                "\n",
                "dataTestSet.dropna()\n",
                "\n",
                "## PREPROCESS : RMOUTLIERS \n",
                "Q1=dataTrainSet.quantile(0.01)\n",
                "Q3=dataTrainSet.quantile(0.8)\n",
                "IQR = Q3 - Q1\n",
                "dataTrainSet[~((dataTrainSet < (Q1 - 1.5 * IQR)) | (dataTrainSet > (Q3 + 1.5 * IQR))).any(axis = 1)]\n",
                "\n",
                "Q1=dataTestSet.quantile(0.01)\n",
                "Q3=dataTestSet.quantile(0.8)\n",
                "IQR = Q3 - Q1\n",
                "dataTestSet[~((dataTestSet < (Q1 - 1.5 * IQR)) | (dataTestSet > (Q3 + 1.5 * IQR))).any(axis = 1)]\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a2da7187",
            "metadata": {
                
            },
            "source": "SPLITTING"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "2d503f2c",
            "metadata": {
                
            },
            "outputs": [
                
            ],
            "source": [
                "##DATASET SPLIT\n",
                "X_train, y_train = dataTrainSet.drop(['label'], axis = 1), dataTrainSet['label']\n",
                ""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bcaed3c9",
            "metadata": {
                
            },
            "source": "TRANSFORMATION"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "666b02be",
            "metadata": {
                
            },
            "outputs": [
                
            ],
            "source": [
                "###### ---- TRANSFORMATION PHASE ---- ######\n",
                "# MinMax TRANSFORMATION\n",
                "minMax01 = MinMaxScaler(feature_range=(0,1),clip=False,copy=True)\n",
                "\n",
                "# PCA TRANSFORMATION\n",
                "pca01 = PCA(n_components=0.62)\n",
                "\n",
                "pca02 = PCA(n_components=0.41)\n",
                "\n",
                "# STANDARDSCALER TRANSFORMATION\n",
                "standardScaler1 = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
                "\n",
                " ## ---- TRANSFORMATION PROCESSING ---- ##\n",
                "### Transformation : 1\n",
                "X_train_minMax01 = minMax01.fit_transform(X_train)\n",
                "X_train_t1 = pca01.fit_transform(X_train_minMax01)\n",
                "### Transformation : 2\n",
                "X_train_minMax01 = minMax01.fit_transform(X_train)\n",
                "X_train_t2 = pca02.fit_transform(X_train_minMax01)\n",
                ""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3e24e55f",
            "metadata": {
                
            },
            "source": "TRAINING"
        },
        {
            "cell_type": "markdown",
            "id": "5525c001",
            "metadata": {
                
            },
            "source": "KNN CLASSIFIER"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "4d84091c",
            "metadata": {
                
            },
            "outputs": [
                
            ],
            "source": [
                "kfold_knn1=StratifiedKFold(n_splits=2, shuffle = True)\n",
                "pipe_knn1= Pipeline([('clf_knn', KNeighborsClassifier())])\n",
                "distribution_knn1_param={'clf_knn__n_neighbors': sp_randint(1,11),'clf_knn__algorithm': ['auto'] }\n",
                "rs_knn1 =RandomizedSearchCV(estimator= pipe_knn1,param_distributions = distribution_knn1_param, cv =kfold_knn1,  verbose = 2, n_jobs = -1, n_iter = 5)\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "8adb85b6",
            "metadata": {
                
            },
            "outputs": [
                
            ],
            "source": [
                "kfold_knn2=StratifiedKFold(n_splits=2, shuffle = True)\n",
                "pipe_knn2= Pipeline([('clf_knn', KNeighborsClassifier())])\n",
                "distribution_knn2_param={'clf_knn__n_neighbors': sp_randint(1,10),'clf_knn__algorithm': ['auto'] }\n",
                "rs_knn2 =RandomizedSearchCV(estimator= pipe_knn2,param_distributions = distribution_knn2_param, cv =kfold_knn2,  verbose = 2, n_jobs = -1, n_iter = 5)\n",
                ""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6675f07d",
            "metadata": {
                
            },
            "source": "GAUSSIAN CLASSIFIER"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "c52dee03",
            "metadata": {
                
            },
            "outputs": [
                
            ],
            "source": [
                "kfold_gaussian1=StratifiedKFold(n_splits=5, shuffle = True)\n",
                "pipe_gaussian1= Pipeline([('clf_nb', GaussianNB())])\n",
                "distribution_gaussian1_param={'clf_nb__var_smoothing': np.logspace(-5, 0, 5) }\n",
                "rs_gaussian1 =RandomizedSearchCV(estimator= pipe_gaussian1,param_distributions = distribution_gaussian1_param, cv =kfold_gaussian1,  verbose = 2, n_jobs = -1, n_iter = 5)\n",
                ""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "483b7416",
            "metadata": {
                
            },
            "source": "RANDOMFOREST CLASSIFIER"
        },
        {
            "cell_type": "markdown",
            "id": "1b101afc",
            "metadata": {
                
            },
            "source": "COMPARISON"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "ffb3ab1f",
            "metadata": {
                
            },
            "outputs": [
                
            ],
            "source": [
                "## # validation + comparaison\n",
                "scoring = {'acc' : 'accuracy'}\n",
                "scores = dict()\n",
                "test_acc_coef = 10\n",
                "fit_time_coef = 3\n",
                "\n",
                "# GAUSSIAN1\n",
                "scores['gaussian1'] = {}\n",
                "scores['gaussian1']['test_acc'] = []\n",
                "scores['gaussian1']['fit_time'] = []\n",
                "\n",
                "scores_gaussian1 = cross_validate(rs_gaussian1,X_train_t1, y_train, cv=5, scoring = scoring)\n",
                "test_acc_gaussian1 = np.mean(scores_gaussian1['test_acc'])\n",
                "fit_time_gaussian1 = np.mean(scores_gaussian1['fit_time'])\n",
                "\n",
                "scores['gaussian1']['test_acc'] = scores_gaussian1['test_acc']\n",
                "scores['gaussian1']['fit_time'] = scores_gaussian1['fit_time']\n",
                "\n",
                "# KNN1\n",
                "scores['knn1'] = {}\n",
                "scores['knn1']['test_acc'] = []\n",
                "scores['knn1']['fit_time'] = []\n",
                "\n",
                "scores_knn1 = cross_validate(rs_knn1,X_train_t2, y_train, cv=5, scoring = scoring)\n",
                "test_acc_knn1 = np.mean(scores_knn1['test_acc'])\n",
                "fit_time_knn1 = np.mean(scores_knn1['fit_time'])\n",
                "\n",
                "scores['knn1']['test_acc'] = scores_knn1['test_acc']\n",
                "scores['knn1']['fit_time'] = scores_knn1['fit_time']\n",
                "\n",
                "# COMPUTE GLOBAL SCORE\n",
                "models_scores = {}\n",
                "models_scores['gaussian1'] = 1 * (test_acc_gaussian1 * test_acc_coef) * (fit_time_coef / (1+fit_time_gaussian1))\n",
                "models_scores['knn1'] = 1 * (test_acc_knn1 * test_acc_coef) * (fit_time_coef / (1+fit_time_knn1))\n",
                "\n",
                "# WINNER MODEL\n",
                "winner_model = max(models_scores.items(), key=operator.itemgetter(1))[0]\n",
                "print('winner model :',winner_model)\n",
                "\n",
                "\n",
                "# COMPARISON CHART\n",
                "plt.scatter(scores['gaussian1']['test_acc'], scores['gaussian1']['fit_time'], marker='x', color='#c7a23d', label='gaussian1')\n",
                "plt.scatter(scores['knn1']['test_acc'], scores['knn1']['fit_time'], marker='x', color='#71fdcf', label='knn1')\n",
                "plt.title('MODELS COMPARISON')\n",
                "plt.xlabel('accuracy')\n",
                "plt.ylabel('fit_time(sec)')\n",
                "plt.legend(loc='lower right', bbox_to_anchor=(1.3,0))\n",
                "plt.show()\n",
                "\n",
                "\n",
                "# COMPARISON TABLE\n",
                "models_scores['gaussian1'] = np.round(models_scores['gaussian1'],3)\n",
                "models_scores['knn1'] = np.round(models_scores['knn1'],3)\n",
                "scores['gaussian1']['test_acc'] = np.round(np.average(scores['gaussian1']['test_acc']),3)\n",
                "scores['knn1']['test_acc'] = np.round(np.average(scores['knn1']['test_acc']),3)\n",
                "scores['gaussian1']['fit_time'] = np.round(np.average(scores['gaussian1']['fit_time']),3)\n",
                "scores['knn1']['fit_time'] = np.round(np.average(scores['knn1']['fit_time']),3)\n",
                "\n",
                "fig, ax = plt.subplots()\n",
                "fig.patch.set_visible(False)\n",
                "ax.axis('off')\n",
                "ax.axis('tight')\n",
                "df = pd.DataFrame([['test_acc', scores['gaussian1']['test_acc'],scores['knn1']['test_acc']],['fit_time', scores['gaussian1']['fit_time'],scores['knn1']['fit_time']],['total', models_scores['gaussian1'], models_scores['knn1'],]],columns=['metric','gaussian1','knn1'])\n",
                "ax.table(cellText=df.values, colLabels=df.columns, loc='center')\n",
                "fig.tight_layout()\n",
                "plt.show()\n",
                ""
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}